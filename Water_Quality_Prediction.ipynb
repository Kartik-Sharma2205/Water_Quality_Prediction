{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"../input/water-potability/water_potability.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.717811Z","iopub.execute_input":"2023-05-08T08:57:27.718267Z","iopub.status.idle":"2023-05-08T08:57:27.75226Z","shell.execute_reply.started":"2023-05-08T08:57:27.718228Z","shell.execute_reply":"2023-05-08T08:57:27.751011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape of the data\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.754322Z","iopub.execute_input":"2023-05-08T08:57:27.754771Z","iopub.status.idle":"2023-05-08T08:57:27.761616Z","shell.execute_reply.started":"2023-05-08T08:57:27.754723Z","shell.execute_reply":"2023-05-08T08:57:27.760498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 3276 rows and 10 columns","metadata":{}},{"cell_type":"code","source":"#Check for missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.76399Z","iopub.execute_input":"2023-05-08T08:57:27.764445Z","iopub.status.idle":"2023-05-08T08:57:27.777109Z","shell.execute_reply.started":"2023-05-08T08:57:27.764397Z","shell.execute_reply":"2023-05-08T08:57:27.77583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping missing values\n#because water quality is a sensitive data, we cannot tamper with the data by imputing mean, median, mode\ndf= df.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.778873Z","iopub.execute_input":"2023-05-08T08:57:27.77925Z","iopub.status.idle":"2023-05-08T08:57:27.791103Z","shell.execute_reply.started":"2023-05-08T08:57:27.779212Z","shell.execute_reply":"2023-05-08T08:57:27.789962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Potability.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.79265Z","iopub.execute_input":"2023-05-08T08:57:27.793082Z","iopub.status.idle":"2023-05-08T08:57:27.805211Z","shell.execute_reply.started":"2023-05-08T08:57:27.793041Z","shell.execute_reply":"2023-05-08T08:57:27.803989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndf.Potability.value_counts().plot(kind ='pie')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.806721Z","iopub.execute_input":"2023-05-08T08:57:27.807106Z","iopub.status.idle":"2023-05-08T08:57:27.903602Z","shell.execute_reply.started":"2023-05-08T08:57:27.807069Z","shell.execute_reply":"2023-05-08T08:57:27.902332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus it is an imbalanced dataset, since 0 is much more 1 (1998>1278)\nSo we need to balance the data so that there is no biasedness.","metadata":{}},{"cell_type":"code","source":"zero  = df[df['Potability']==0]   #zero values in Potability column\none = df[df['Potability']==1]  # one values in Potability column\nfrom sklearn.utils import resample\n#minority class that  is 1, we need to upsample/increase that class so that there is no bias\n#n_samples = 1998 means we want 1998 sample of class 1, since there are 1998 samples of class 0\ndf_minority_upsampled = resample(one, replace = True, n_samples = 1200) \n#concatenate\ndf = pd.concat([zero, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.905411Z","iopub.execute_input":"2023-05-08T08:57:27.905871Z","iopub.status.idle":"2023-05-08T08:57:27.918372Z","shell.execute_reply.started":"2023-05-08T08:57:27.905821Z","shell.execute_reply":"2023-05-08T08:57:27.917463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Potability.value_counts().plot(kind ='pie')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:27.921273Z","iopub.execute_input":"2023-05-08T08:57:27.922158Z","iopub.status.idle":"2023-05-08T08:57:28.01042Z","shell.execute_reply.started":"2023-05-08T08:57:27.922079Z","shell.execute_reply":"2023-05-08T08:57:28.009402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it's perfect!","metadata":{}},{"cell_type":"code","source":"#understanding correlation\nplt.figure(figsize = (15,9))\nsns.heatmap(df.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:28.01227Z","iopub.execute_input":"2023-05-08T08:57:28.012705Z","iopub.status.idle":"2023-05-08T08:57:28.838592Z","shell.execute_reply.started":"2023-05-08T08:57:28.012658Z","shell.execute_reply":"2023-05-08T08:57:28.837545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=df[\"ph\"], y=df[\"Hardness\"], hue=df.Potability,\ndata=df)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:28.840004Z","iopub.execute_input":"2023-05-08T08:57:28.840324Z","iopub.status.idle":"2023-05-08T08:57:29.130418Z","shell.execute_reply.started":"2023-05-08T08:57:28.84029Z","shell.execute_reply":"2023-05-08T08:57:29.129514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=df[\"ph\"], y=df[\"Chloramines\"], hue=df.Potability,\ndata=df)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.132458Z","iopub.execute_input":"2023-05-08T08:57:29.133081Z","iopub.status.idle":"2023-05-08T08:57:29.438996Z","shell.execute_reply.started":"2023-05-08T08:57:29.133041Z","shell.execute_reply":"2023-05-08T08:57:29.438054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no particular pattern!","metadata":{}},{"cell_type":"code","source":"df.corr().abs()['Potability'].sort_values(ascending = False)\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# calculate absolute correlation values between each feature and target variable\ncorr_values = df.corr().abs()['Potability'].sort_values(ascending=False)\n\n# create bar chart\nplt.figure(figsize=(10,6))\nplt.bar(corr_values.index, corr_values.values, color='blue')\n\n# set chart title and axis labels\nplt.title('Correlation Between Features and Potability', fontsize=16)\nplt.xlabel('Features', fontsize=12)\nplt.ylabel('Correlation Value', fontsize=12)\n\n# rotate x-axis labels for better readability\nplt.xticks(rotation=90)\n\n# display plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.44073Z","iopub.execute_input":"2023-05-08T08:57:29.441331Z","iopub.status.idle":"2023-05-08T08:57:29.656087Z","shell.execute_reply.started":"2023-05-08T08:57:29.441291Z","shell.execute_reply":"2023-05-08T08:57:29.654827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"highest correlation with Potability is solids with 5.24% only","metadata":{}},{"cell_type":"code","source":"X = df.drop(['Potability'], axis = 1)\ny = df['Potability']","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.658415Z","iopub.execute_input":"2023-05-08T08:57:29.658782Z","iopub.status.idle":"2023-05-08T08:57:29.665467Z","shell.execute_reply.started":"2023-05-08T08:57:29.658747Z","shell.execute_reply":"2023-05-08T08:57:29.664286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nfeatures= X.columns\nX[features] = sc.fit_transform(X[features])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.667124Z","iopub.execute_input":"2023-05-08T08:57:29.667491Z","iopub.status.idle":"2023-05-08T08:57:29.685146Z","shell.execute_reply.started":"2023-05-08T08:57:29.667452Z","shell.execute_reply":"2023-05-08T08:57:29.683926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC, LinearSVC\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.686774Z","iopub.execute_input":"2023-05-08T08:57:29.687191Z","iopub.status.idle":"2023-05-08T08:57:29.69467Z","shell.execute_reply.started":"2023-05-08T08:57:29.687152Z","shell.execute_reply":"2023-05-08T08:57:29.693461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.696161Z","iopub.execute_input":"2023-05-08T08:57:29.696475Z","iopub.status.idle":"2023-05-08T08:57:29.710613Z","shell.execute_reply.started":"2023-05-08T08:57:29.696444Z","shell.execute_reply":"2023-05-08T08:57:29.709371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyper-parameter Tuning ;)","metadata":{}},{"cell_type":"code","source":"#Hyperparameter tuning ;)\n\nlr = LogisticRegression(random_state=42)\n\nsvm = SVC()\n\nknn = KNeighborsClassifier()\n\ndt = DecisionTreeClassifier()\n\nrf = RandomForestClassifier()\n\nada = AdaBoostClassifier()\n\nxgb =XGBClassifier(eval_metric = 'logloss', use_label_encoder=False)\n\n#SVM\n# define hyperparameters for SVM\nsvm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n\n# define grid search object\ngrid_svm = GridSearchCV(estimator=svm, param_grid=svm_param_grid, cv=5, scoring='accuracy')\n\npara_knn = {'n_neighbors':np.arange(1, 50)}  #parameters of knn\ngrid_knn = GridSearchCV(knn, param_grid=para_knn, cv=5) #search knn for 5 fold cross validation\n\n#parameters for decision tree\npara_dt = {'criterion':['gini','entropy'],'max_depth':np.arange(1, 50), 'min_samples_leaf':[1,2,4,5,10,20,30,40,80,100]}\ngrid_dt = GridSearchCV(dt, param_grid=para_dt, cv=5) #grid search decision tree for 5 fold cv\n#\"gini\" for the Gini impurity and “entropy” for the information gain.\n#min_samples_leaf: The minimum number of samples required to be at a leaf node, have the effect of smoothing the model\n\n#parameters for random forest\n#n_estimators: The number of trees in the forest.\nparams_rf = {'n_estimators':[100,200, 350, 500], 'min_samples_leaf':[2, 10, 30]}\ngrid_rf = GridSearchCV(rf, param_grid=params_rf, cv=5)\n\n#parameters fpr AdaBoost\nparams_ada = {'n_estimators': [50,100,250,400,500,600], 'learning_rate': [0.2,0.5,0.8,1]}\ngrid_ada =  GridSearchCV(ada, param_grid=params_ada, cv=5)\n\n#XGBoost\n#parameters for xgboost\nparams_xgb = {'n_estimators': [50,100,250,400,600,800,1000], 'learning_rate': [0.2,0.5,0.8,1]}\nrs_xgb =  RandomizedSearchCV(xgb, param_distributions=params_xgb, cv=5)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.712513Z","iopub.execute_input":"2023-05-08T08:57:29.71316Z","iopub.status.idle":"2023-05-08T08:57:29.72633Z","shell.execute_reply.started":"2023-05-08T08:57:29.713108Z","shell.execute_reply":"2023-05-08T08:57:29.725372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers = [('Logistic Regression', lr), ('SVM', svm), ('K Nearest Neighbours', knn),\n               ('Decision Tree', dt), ('Random Forest', rf), ('AdaBoost', ada), ('XGBoost', xgb)]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.727607Z","iopub.execute_input":"2023-05-08T08:57:29.728143Z","iopub.status.idle":"2023-05-08T08:57:29.742838Z","shell.execute_reply.started":"2023-05-08T08:57:29.728097Z","shell.execute_reply":"2023-05-08T08:57:29.741839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nfor classifier_name, classifier in classifiers:\n \n    # Fit clf to the training set\n    classifier.fit(X_train, y_train)    \n   \n    # Predict y_pred\n    y_pred = classifier.predict(X_test)\n    accuracy = accuracy_score(y_test,y_pred)\n    \n    # Evaluate clf's accuracy on the test set\n    print('{:s} : {:.2f}'.format(classifier_name, accuracy))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:29.745555Z","iopub.execute_input":"2023-05-08T08:57:29.746088Z","iopub.status.idle":"2023-05-08T08:57:31.602526Z","shell.execute_reply.started":"2023-05-08T08:57:29.746047Z","shell.execute_reply":"2023-05-08T08:57:31.601497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nclassifiers = [('Logistic Regression', lr), ('SVM', svm), ('K Nearest Neighbours', knn), ('Decision Tree', dt), ('Random Forest', rf), ('AdaBoost', ada), ('XGBoost', xgb)]\n\nfor clf_name, clf in classifiers:\n    print(f\"Classification Report for {clf_name}:\")\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(classification_report(y_test, y_pred))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:33.534076Z","iopub.execute_input":"2023-05-08T08:57:33.534399Z","iopub.status.idle":"2023-05-08T08:57:35.332848Z","shell.execute_reply.started":"2023-05-08T08:57:33.53437Z","shell.execute_reply":"2023-05-08T08:57:35.331779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\n# Generate some data for classification\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define the base models\nlr = LogisticRegression(random_state=42)\nsvm = SVC(C=10, gamma='scale', kernel='rbf', probability=True)\nknn = KNeighborsClassifier(n_neighbors=1)\ndt = DecisionTreeClassifier(criterion='gini', max_depth=27, min_samples_leaf=1)\nrf = RandomForestClassifier(n_estimators=350, min_samples_leaf=2)\nada = AdaBoostClassifier(n_estimators=600, learning_rate=1)\nxgb_clf = xgb.XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.1)\n\n# Define the stacking classifier\nestimators = [('lr', lr), ('svm', svm), ('knn', knn), ('dt', dt), ('rf', rf), ('ada', ada), ('xgb', xgb_clf)]\nstacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n\n# Fit the stacking classifier to the training data\nstacking.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = stacking.predict(X_test)\n\n# Calculate the accuracy of the stacking classifier\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:35.334621Z","iopub.execute_input":"2023-05-08T08:57:35.335333Z","iopub.status.idle":"2023-05-08T08:57:57.173784Z","shell.execute_reply.started":"2023-05-08T08:57:35.335272Z","shell.execute_reply":"2023-05-08T08:57:57.172942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Make predictions on the test data\ny_pred = stacking.predict(X_test)\n\n# Calculate precision, recall, and f1 score\nreport = classification_report(y_test, y_pred)\n\nprint(\"Classification report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:19:21.620193Z","iopub.execute_input":"2023-05-08T09:19:21.620571Z","iopub.status.idle":"2023-05-08T09:19:21.846917Z","shell.execute_reply.started":"2023-05-08T09:19:21.620539Z","shell.execute_reply":"2023-05-08T09:19:21.845728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define the classifiers and their precision scores\nclassifiers = ['SVM', 'KNN', 'DT', 'XGB', 'ADA', 'LR', 'RF', 'SE']\nprecisions = [0.70, 0.65, 0.85, 0.85, 0.65, 0.58, 0.86, 0.97]\n\n# Create a bar graph\nfig, ax = plt.subplots()\nax.bar(classifiers, precisions)\n\n# Set the axis labels and title\nax.set_xlabel('Classifiers')\nax.set_ylabel('Precision')\nax.set_title('Precision scores for different classifiers')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:43:56.612444Z","iopub.execute_input":"2023-05-08T09:43:56.612825Z","iopub.status.idle":"2023-05-08T09:43:56.77497Z","shell.execute_reply.started":"2023-05-08T09:43:56.612791Z","shell.execute_reply":"2023-05-08T09:43:56.773853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define the classifiers and their accuracy scores\nclassifiers = ['SVM', 'KNN', 'DT', 'XGB', 'ADA', 'LR', 'RF', 'SE']\naccuracies = [0.70, 0.63, 0.82, 0.84, 0.60, 0.54, 0.87, 0.96]\n\n# Create a bar graph\nfig, ax = plt.subplots()\nax.bar(classifiers, accuracies)\n\n# Set the axis labels and title\nax.set_xlabel('Classifiers')\nax.set_ylabel('Accuracy')\nax.set_title('Accuracy scores for different classifiers')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:49:04.133701Z","iopub.execute_input":"2023-05-08T09:49:04.134358Z","iopub.status.idle":"2023-05-08T09:49:04.296529Z","shell.execute_reply.started":"2023-05-08T09:49:04.134307Z","shell.execute_reply":"2023-05-08T09:49:04.295401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define the classifiers and their recall scores\nclassifiers = ['SVM', 'KNN', 'DT', 'XGB', 'ADA', 'LR', 'RF', 'SE']\nrecalls = [0.74, 0.65, 0.80, 0.84, 0.56, 0.51, 0.90, 0.95]\n\n# Create a bar graph\nfig, ax = plt.subplots()\nax.bar(classifiers, recalls)\n\n# Set the axis labels and title\nax.set_xlabel('Classifiers')\nax.set_ylabel('Recall')\nax.set_title('Recall scores for different classifiers')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T10:00:44.48429Z","iopub.execute_input":"2023-05-08T10:00:44.484686Z","iopub.status.idle":"2023-05-08T10:00:44.636198Z","shell.execute_reply.started":"2023-05-08T10:00:44.484643Z","shell.execute_reply":"2023-05-08T10:00:44.635249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define the classifiers and their f1-scores\nclassifiers = ['SVM', 'KNN', 'DT', 'XGB', 'ADA', 'LR', 'RF', 'SE']\nf1_scores = [0.72, 0.65, 0.83, 0.85, 0.60, 0.54, 0.88, 0.96]\n\n# Create a bar graph\nfig, ax = plt.subplots()\nax.bar(classifiers, f1_scores)\n\n# Set the axis labels and title\nax.set_xlabel('Classifiers')\nax.set_ylabel('F1-Score')\nax.set_title('F1-Score for different classifiers')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T10:07:20.806203Z","iopub.execute_input":"2023-05-08T10:07:20.806579Z","iopub.status.idle":"2023-05-08T10:07:20.969387Z","shell.execute_reply.started":"2023-05-08T10:07:20.806545Z","shell.execute_reply":"2023-05-08T10:07:20.968341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}